{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f8b727d-6d7a-4a83-b200-ccab1095e29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generated Poem:\n",
      " Here's a poem I came up with:\n",
      "\n",
      "The velvet veil of twilight falls,\n",
      "As stars awaken, one by one, to call\n",
      "The celestial show begins anew,\n",
      "A canvas painted, dark and true.\n",
      "\n",
      "Like diamonds scattered, free and bright,\n",
      "Their twinkling whispers echo through the night.\n",
      "A gentle breeze stirs, a soft sigh,\n",
      "As constellations twirl, and dance, and fly.\n",
      "\n",
      "In this great tapestry of endless blue,\n",
      "Our place is small, yet we are part of it anew.\n",
      "For in the silence, I hear a voice,\n",
      "That speaks to hearts, and makes our souls rejoice.\n",
      "\n",
      "And when I look upon that starry sea,\n",
      "I feel the mystery, and wonder, set me free.\n",
      "The night sky whispers secrets, ancient and true,\n",
      "Reminding us of magic, waiting there for you.\n"
     ]
    }
   ],
   "source": [
    "#Task 13 : LangGraph\n",
    "#Generating poem using LangGraph nodes\n",
    "\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# Define the state\n",
    "class PoemState(TypedDict):\n",
    "    messages: list[HumanMessage | AIMessage | SystemMessage]\n",
    "\n",
    "# Initialize Ollama LLM\n",
    "ollama_llm = OllamaLLM(model=\"llama3\")  # replace \"llama2\" with your Ollama model\n",
    "\n",
    "# generate poem\n",
    "def generate_poem(state: PoemState) -> PoemState:\n",
    "    prompt_messages = state[\"messages\"]\n",
    "    # Ollama expects a single string prompt, so join messages\n",
    "    user_prompt = \"\\n\".join(\n",
    "        msg.content for msg in prompt_messages if isinstance(msg, (HumanMessage, SystemMessage))\n",
    "    )\n",
    "    response = ollama_llm.invoke(user_prompt)  # call Ollama\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "# Create the graph\n",
    "graph = StateGraph(PoemState)\n",
    "graph.add_node(\"poem_node\", generate_poem)\n",
    "graph.add_edge(START, \"poem_node\")\n",
    "graph.add_edge(\"poem_node\", END)\n",
    "compiled_graph = graph.compile()\n",
    "\n",
    "# Initial state\n",
    "initial_state = {\n",
    "    \"messages\": [\n",
    "        SystemMessage(content=\"You are a creative poet.\"),\n",
    "        HumanMessage(content=\"Write a short beautiful poem about the night sky.\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Run the graph\n",
    "result = compiled_graph.invoke(initial_state)\n",
    "\n",
    "# Print the poem\n",
    "for msg in result[\"messages\"]:\n",
    "    if isinstance(msg, AIMessage):\n",
    "        print(\" Generated Poem:\\n\", msg.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd27c72-69b0-4d44-84dc-6f4f52a4c5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
