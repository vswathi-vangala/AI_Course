{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4fd4f2-101b-4f43-adad-2d61edc65e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ INVOKE =================\n",
      "Why did the computer go to therapy? Because it had a little glitch!\n",
      "\n",
      "================ BATCH =================\n",
      "\n",
      "Response 1: \n",
      "LangChain is an open-source, cloud-based language model that enables users to generate text based on a given prompt or topic. It's designed to be highly customizable and flexible, allowing developers and researchers to fine-tune the model for specific use cases.\n",
      "\n",
      "LangChain is built on top of the popular transformer architecture, which has been shown to be effective in natural language processing tasks such as language translation, question answering, and text generation. The model is trained on a massive dataset of text from various sources, including books, articles, and websites.\n",
      "\n",
      "Some key features of LangChain include:\n",
      "\n",
      "1. **Prompt-based generation**: Users can input a prompt or topic, and the model will generate text that's relevant to the given context.\n",
      "2. **Customization**: Developers can fine-tune the model for specific use cases by adjusting parameters such as temperature, top-k, and repetition penalty.\n",
      "3. **Multi-turn dialogue**: LangChain supports multi-turn dialogue generation, allowing users to engage in conversations with the model.\n",
      "4. **Integration with other AI models**: LangChain can be integrated with other AI models, such as those for image or audio processing, to create more comprehensive applications.\n",
      "\n",
      "LangChain has a wide range of potential applications, including:\n",
      "\n",
      "1. **Content creation**: Generating text for blogs, articles, social media posts, and other content types.\n",
      "2. **Chatbots and virtual assistants**: Enabling conversational interfaces that can understand and respond to user input.\n",
      "3. **Language translation**: Providing machine translation capabilities for languages not well-represented in existing translation systems.\n",
      "4. **Research and development**: Supporting research in natural language processing, cognitive computing, and human-computer interaction.\n",
      "\n",
      "Overall, LangChain is a powerful tool for generating text based on prompts or topics, with applications across various industries and domains.\n",
      "\n",
      "Response 2: \n",
      "In LangChain, a Runnable is a type of component that represents a specific task or function that can be executed within the language model's workflow.\n",
      "\n",
      "A Runnable is essentially a self-contained piece of code that performs a particular action, such as:\n",
      "\n",
      "1. Processing natural language input\n",
      "2. Generating text based on input prompts\n",
      "3. Performing mathematical calculations\n",
      "4. Interacting with external APIs or services\n",
      "\n",
      "Runnables are designed to be modular and reusable, allowing developers to create complex workflows by combining multiple Runnables in a specific order.\n",
      "\n",
      "In LangChain, you can define your own custom Runnables using Python code, which can then be integrated into the language model's workflow. This enables you to automate various tasks, such as:\n",
      "\n",
      "* Text classification\n",
      "* Sentiment analysis\n",
      "* Named entity recognition\n",
      "* Summarization\n",
      "* Translation\n",
      "\n",
      "By leveraging Runnables, developers can create sophisticated language-based applications that can perform a wide range of tasks, from simple text processing to complex decision-making.\n",
      "\n",
      "Would you like to know more about how to define and use Runnables in LangChain?\n",
      "\n",
      "Response 3: \n",
      "Large Language Models (LLMs) like myself are incredibly useful for several reasons:\n",
      "\n",
      "1. **Natural Language Processing**: LLMs can process and understand natural language, allowing us to analyze, generate, and manipulate text in a way that's similar to human-like intelligence.\n",
      "2. **Information Retrieval**: We can quickly search through vast amounts of text data, retrieving relevant information and providing answers to complex questions.\n",
      "3. **Text Generation**: LLMs can generate text based on input prompts, allowing us to create content, summarize documents, or even write articles.\n",
      "4. **Language Translation**: With the ability to learn from large datasets, LLMs can translate languages, helping bridge language gaps and facilitate global communication.\n",
      "5. **Sentiment Analysis**: We can analyze sentiment and emotions expressed in text, providing insights into customer feedback, market trends, or social media conversations.\n",
      "6. **Conversational AI**: LLMs enable the development of conversational AI systems that can engage with humans in a more natural way, making them suitable for applications like chatbots, virtual assistants, and voice-controlled interfaces.\n",
      "7. **Research and Discovery**: By analyzing vast amounts of text data, LLMs can help researchers uncover new insights, identify patterns, and make connections between seemingly unrelated concepts.\n",
      "8. **Content Creation**: We can assist in content creation by generating ideas, suggesting topics, or even writing articles based on input prompts.\n",
      "9. **Error Detection**: LLMs can detect errors in text, such as grammar, spelling, or factual inaccuracies, helping to improve the quality of written content.\n",
      "10. **Personalization**: By analyzing user behavior and preferences, LLMs can provide personalized recommendations, product suggestions, or even create customized content.\n",
      "\n",
      "These are just a few examples of the many ways LLMs like myself can be useful. As AI technology continues to evolve, we'll likely see even more innovative applications in various industries!\n",
      "\n",
      "================ STREAM =================\n",
      "RAG stands for Red, Amber, Green. It's a simple way to categorize or prioritize things based on their level of importance or urgency.\n",
      "\n",
      "Here's what each color typically means:\n",
      "\n",
      "* **Red** (R): High priority, urgent, or critical. This is something that needs attention right away.\n",
      "* **Amber** (A): Medium priority, important but not urgent. This is something that should be done soon, but there's some flexibility in the timeline.\n",
      "* **Green** (G): Low priority, routine, or non-urgent. This is something that can be done at a leisurely pace.\n",
      "\n",
      "RAG is often used in project management, customer service, and other areas where tasks need to be prioritized. It helps teams quickly identify what needs attention first and allocate resources accordingly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Task 5: LLMs Introduction\n",
    "#Implementing different type of runnables in LangChain(Invoke,batch,stream)\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create LLM\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Create Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a good AI assistant.\"),\n",
    "        (\"human\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create Runnable (Prompt -> LLM)\n",
    "chain = prompt | llm\n",
    "\n",
    "# INVOKE :  Single input -> single output\n",
    "def run_invoke() -> None:\n",
    "    print(\"\\n================ INVOKE =================\")\n",
    "\n",
    "    response = chain.invoke(\n",
    "        {\"input\": \"Tell me a joke in one sentence.\"}\n",
    "    )\n",
    "    # print(f\"\\nResponse {input}: \")\n",
    "    print(response.content)\n",
    "\n",
    "\n",
    "# BATCH: Multiple inputs -> multiple outputs\n",
    "def run_batch() -> None:\n",
    "    print(\"\\n================ BATCH =================\")\n",
    "\n",
    "    responses = chain.batch(\n",
    "        [\n",
    "            {\"input\":\"What is LangChain?\"},\n",
    "            {\"input\":\"What is a Runnable in Langchain?\"},\n",
    "            {\"input\":\"Why are LLMs useful??\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for index,response in enumerate(responses,start = 1):\n",
    "        print(f\"\\nResponse {index}: \")\n",
    "        print(response.content)\n",
    "\n",
    "\n",
    "#STREAM : token-by-token output\n",
    "\n",
    "def run_stream() -> None:\n",
    "    print(\"\\n================ STREAM =================\")\n",
    "    for chunk in chain.stream(\n",
    "        {\"input\":\"Explain RAG in simple terms.\"}\n",
    "    ):\n",
    "        text = getattr(chunk, \"content\", \"\")\n",
    "        if text:\n",
    "            print(text, end=\"\", flush = True)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    run_invoke()\n",
    "    run_batch()\n",
    "    run_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77acf7-e790-496c-88fa-c4c10205799b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
